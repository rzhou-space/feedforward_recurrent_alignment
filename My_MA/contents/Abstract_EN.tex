\documentclass[11pt]{article}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{float}
\usepackage{lmodern,amsmath,amssymb,amstext,amsfonts,mathrsfs,graphicx,caption, subcaption}
\usepackage[width=14cm]{geometry}
\usepackage[colorlinks,pdfpagelabels,pdfstartview = FitV,bookmarksnumbered = true, bookmarksopenlevel=section, linkcolor = black,hypertexnames = false,citecolor = black,pdfpagelabels=false]{hyperref}
\usepackage{tablefootnote}
%\usepackage{rotating}
\usepackage{textcmds, enumitem}
\usepackage{sidecap} %, indentfirst
\usepackage[labelfont={bf,sf},font={small},labelsep=space]{caption}
\usepackage{chngcntr} % 			** Damit die Bilder Tabellen und Gleichungen 
\counterwithin{figure}{section}	%	** alle nach Kapiteln nummeriert sind.
\counterwithin{table}{section}%		**
\counterwithin{equation}{section}%	**	

\begin{document}
	
	\section*{Abstract}
	
	Theoretical neuroscience helps to understand the underlying mechanisms of neural systems by theoretical modeling and analysis. The dynamics of the cortical networks can be modeled by feedforward recurrent networks. If modeling novel visual input by feedforward input, the alignment between the feedforward network and recurrent network can determine the reliability of final response representations. This can help to explore the mechanisms that enable endogenously generated networks to form mature representations with the onset of sensory experience. However, the conceptual modeling before only cover the case of idealized symmetric neural interactions. Here we extend the previous modeling with more general network interaction structures and explore the performance of modeling under more complex circumstances.
	For asymmetric neural interactions, symmetrization can keep most of the pattern information and allow alignment in the real-number plane. White-noise evoked activity pattern is a possible candidate for alignment to approximate unknown recurrent interaction. Embedding Hebbian learning in the model shows the potential of plasticity for exploring the mechanisms. The work demonstrates the different modifications for different network structure conditions that enable the feedforward recurrent alignment. 
	The theoretical explorations of alignment between feedforward and recurrent networks under different interaction conditions can help the prior modeling to become more general. Besides, the results can provide new perspectives to deepen the understanding of mechanisms for experience-driven developments in cortical networks. 
\end{document}