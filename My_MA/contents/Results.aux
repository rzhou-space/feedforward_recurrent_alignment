\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{dayan2005theoretica}
\citation{tragenap2023nature}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Results}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Response Properties from symmetrical Recurrent Interaction Networks in Correlation with Feedforward Recurrent Alignment}{1}{subsection.2}\protected@file@percent }
\newlabel{sec:results_symmetric}{{1.1}{1}{Response Properties from symmetrical Recurrent Interaction Networks in Correlation with Feedforward Recurrent Alignment}{subsection.2}{}}
\newlabel{eq:response_amplification}{{1.1}{1}{Response Properties from symmetrical Recurrent Interaction Networks in Correlation with Feedforward Recurrent Alignment}{equation.3}{}}
\newlabel{eq:selective_amplification}{{1.2}{1}{Response Properties from symmetrical Recurrent Interaction Networks in Correlation with Feedforward Recurrent Alignment}{equation.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.1}Trial-to-Trial Correlation increases with larger Alignment}{1}{subsubsection.5}\protected@file@percent }
\citation{tragenap2023nature}
\citation{tragenap2023nature}
\newlabel{eq:ascending_order}{{1.4}{2}{Trial-to-Trial Correlation increases with larger Alignment}{equation.7}{}}
\newlabel{SC@1}{{\caption@xref {??}{ on input line 61}}{2}{Trial-to-Trial Correlation increases with larger Alignment}{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces \textbf  {Correlation between feedforward recurrent alignment and trial to trial correlation.} Inputs aligned to eigenvectors $\mathbf  {e}_i$ of interaction matrix $J$ in the ascending order of eigenvalues (\ref  {eq:ascending_order}), resulting the feedforward recurrent alignment varies approximately between $\lambda _{\text  {min}}$ and $\lambda _{\text  {max}}$. For each input alignment to an eigenvector, $N$ trials of evoked responses were generated for calculation of the trial-to-trial correlation.\relax }}{2}{figure.caption.8}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:ttc_ffrec_sym}{{1.1}{2}{\textbf {Correlation between feedforward recurrent alignment and trial to trial correlation.} Inputs aligned to eigenvectors $\mathbf {e}_i$ of interaction matrix $J$ in the ascending order of eigenvalues (\ref {eq:ascending_order}), resulting the feedforward recurrent alignment varies approximately between $\lambda _{\text {min}}$ and $\lambda _{\text {max}}$. For each input alignment to an eigenvector, $N$ trials of evoked responses were generated for calculation of the trial-to-trial correlation.\relax }{figure.caption.8}{}}
\citation{bartolo2020dimensionality}
\citation{badre2021dimensionality}
\citation{badre2021dimensionality}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.2}Intra-Trial Stability increases with larger Alignment}{3}{subsubsection.9}\protected@file@percent }
\newlabel{SC@2}{{\caption@xref {??}{ on input line 80}}{3}{Intra-Trial Stability increases with larger Alignment}{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces \textbf  {Correlation between feedforward recurrent alignment and intra-trial stability.} Inputs aligned to eigenvectors $\mathbf  {e}_i$ of interaction matrix $J$ in the ascending order of eigenvalues (\ref  {eq:ascending_order}), resulting the feedforward recurrent alignment varies approximately between $\lambda _{\text  {min}}$ and $\lambda _{\text  {max}}$. For each input alignment to an eigenvector, the intra-trial stability is calculated with the evoked steady state response.\relax }}{3}{figure.caption.10}\protected@file@percent }
\newlabel{fig:its_ffrec_sym}{{1.2}{3}{\textbf {Correlation between feedforward recurrent alignment and intra-trial stability.} Inputs aligned to eigenvectors $\mathbf {e}_i$ of interaction matrix $J$ in the ascending order of eigenvalues (\ref {eq:ascending_order}), resulting the feedforward recurrent alignment varies approximately between $\lambda _{\text {min}}$ and $\lambda _{\text {max}}$. For each input alignment to an eigenvector, the intra-trial stability is calculated with the evoked steady state response.\relax }{figure.caption.10}{}}
\citation{tragenap2023nature}
\citation{tragenap2023nature}
\citation{tragenap2023nature}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.3}Dimensionality decreases with larger Alignment}{4}{subsubsection.11}\protected@file@percent }
\newlabel{eq:descding_order}{{1.5}{4}{Dimensionality decreases with larger Alignment}{equation.12}{}}
\citation{tragenap2023nature}
\citation{imaizumi2018spontaneous}
\newlabel{fig:dim_sym}{{1.3b}{5}{\relax }{figure.caption.13}{}}
\newlabel{sub@fig:dim_sym}{{b}{5}{\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces \textbf  {The correlation between dimensionality and feedforward recurrent alignment.} Prior experimental observation suggests that the dimensionality decreases from prior to post eye opening \cite  {tragenap2023nature}. With the feedforward recurrent alignment hypothesis, dimensionality property of the neural representation could be captured. \textbf  {(a)} Principal component analysis for the evoked activity under best alignment between inputs and dominant eigenvector and spontaneous random alignment. Red line for maximal alignment and green line for spontaneous alignment. \text  {(b)} Achieve the correlation between dimensionality and feedforward recurrent alignment with analytical (\ref  {eq:dim_analytical_sym}) and empirically (\ref  {eq:dim_empirical_sym}). The green line displays the analytical approximation for dimensionality and the blue dots for empirical approximation.\relax }}{5}{figure.caption.13}\protected@file@percent }
\newlabel{fig:correlation_dim_ffrec_sym}{{1.3}{5}{\textbf {The correlation between dimensionality and feedforward recurrent alignment.} Prior experimental observation suggests that the dimensionality decreases from prior to post eye opening \cite {tragenap2023nature}. With the feedforward recurrent alignment hypothesis, dimensionality property of the neural representation could be captured. \textbf {(a)} Principal component analysis for the evoked activity under best alignment between inputs and dominant eigenvector and spontaneous random alignment. Red line for maximal alignment and green line for spontaneous alignment. \text {(b)} Achieve the correlation between dimensionality and feedforward recurrent alignment with analytical (\ref {eq:dim_analytical_sym}) and empirically (\ref {eq:dim_empirical_sym}). The green line displays the analytical approximation for dimensionality and the blue dots for empirical approximation.\relax }{figure.caption.13}{}}
\citation{tragenap2023nature}
\citation{tragenap2023nature}
\citation{tragenap2023nature}
\citation{tragenap2023nature}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.4}Alignment to spontaneous activity increases with larger Alignment}{6}{subsubsection.14}\protected@file@percent }
\newlabel{fig:variance_ratio_sym}{{1.4a}{6}{\relax }{figure.caption.15}{}}
\newlabel{sub@fig:variance_ratio_sym}{{a}{6}{\relax }{figure.caption.15}{}}
\newlabel{fig:align_spont_sym}{{1.4b}{6}{\relax }{figure.caption.15}{}}
\newlabel{sub@fig:align_spont_sym}{{b}{6}{\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces \textbf  {Correlation between alignment to spontaneous activity and feedforward recurrent alignment.} Spontaneous activity reflects inputs from wide range of different sources and considered to already aligned to the recurrent network\cite  {tragenap2023nature}. Aligning activity patterns to spontaneous activity is in principle to explain the activity pattern by the principal components of spontaneous activity. \textbf  {(a)} Variance ratio (\ref  {eq:var_explain_spont_act_sym}) of spontaneous activity, evoked activity by feedforward input maximally aligning to recurrent network, and evoked activity by randomly aligning to recurrent network explained by principal components of spontaneous activity. The red line illustrates the variance ratio of spontaneous activity, blue line the maximal alignment, and green line the random alignment. Shadow shows the 95\% confident interval for 50 networks. \text  {(b)} The correlation between final alignment score to spontaneous activity and feedforward recurrent alignment better than random alignment calculated with (\ref  {eq:align_to_spont_act_sym}). The eigenvalues are ordered in the same way as (\ref  {eq:descding_order}). Only the first half eigenvectors are taken into account to determine the correlation.\relax }}{6}{figure.caption.15}\protected@file@percent }
\newlabel{fig:align_spont_act_sym}{{1.4}{6}{\textbf {Correlation between alignment to spontaneous activity and feedforward recurrent alignment.} Spontaneous activity reflects inputs from wide range of different sources and considered to already aligned to the recurrent network\cite {tragenap2023nature}. Aligning activity patterns to spontaneous activity is in principle to explain the activity pattern by the principal components of spontaneous activity. \textbf {(a)} Variance ratio (\ref {eq:var_explain_spont_act_sym}) of spontaneous activity, evoked activity by feedforward input maximally aligning to recurrent network, and evoked activity by randomly aligning to recurrent network explained by principal components of spontaneous activity. The red line illustrates the variance ratio of spontaneous activity, blue line the maximal alignment, and green line the random alignment. Shadow shows the 95\% confident interval for 50 networks. \text {(b)} The correlation between final alignment score to spontaneous activity and feedforward recurrent alignment better than random alignment calculated with (\ref {eq:align_to_spont_act_sym}). The eigenvalues are ordered in the same way as (\ref {eq:descding_order}). Only the first half eigenvectors are taken into account to determine the correlation.\relax }{figure.caption.15}{}}
\citation{tragenap2023nature}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Evaluation of Feedforward Recurrent Alignment Modulations for asymmetric Recurrent Interaction Networks}{8}{subsection.16}\protected@file@percent }
\newlabel{sec:asymmetric_results}{{1.2}{8}{Evaluation of Feedforward Recurrent Alignment Modulations for asymmetric Recurrent Interaction Networks}{subsection.16}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Monotony of Feedforward Recurrent Alignment Score in dependence of Eigenvalues}{8}{subsubsection.17}\protected@file@percent }
\newlabel{fig:ffrec_real_part}{{1.5a}{9}{\relax }{figure.caption.18}{}}
\newlabel{sub@fig:ffrec_real_part}{{a}{9}{\relax }{figure.caption.18}{}}
\newlabel{fig:ffrec_mag}{{1.5b}{9}{\relax }{figure.caption.18}{}}
\newlabel{sub@fig:ffrec_mag}{{b}{9}{\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces \textbf  {Correlation between eigenvalues and feedforward recurrent alignment.} To verify the considered modifications, a positive correlation between eigenvalues and feedforward recurrent alignment is advantageous. Represent the correlation in the complex plane, since eigenvalues are complex. Color bar indicate the size of feedforward recurrent alignment. The darker the color, the larger the alignment score. \textbf  {(a)} Representation of alignment score calculated with modification \ref  {sec:modicication_real_part} (\ref  {eq:ffrec_real_part}) in complex plane. \textbf  {(b)} Representation of alignment score calculated with modification \ref  {sec:modification_magnitude} (\ref  {eq:ffrec_mag}) in complex plane.\relax }}{9}{figure.caption.18}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Modification 1}{9}{section*.19}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Modification 2}{10}{section*.22}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Modification 3}{10}{section*.24}\protected@file@percent }
\newlabel{SC@3}{{\caption@xref {??}{ on input line 240}}{10}{Modification 3}{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces \textbf  {Positive correlation between feedforward recurrent alignment score and eigenvalues of symmetrized network.} Project the inputs to the eigenvectors of symmetrized network to refer the development instead of the projection to the original asymmetric network. The correlation between the alignment score (y-axis) based on the original recurrent network to the eigenvalues of symmetrized network (x-axis) remains positive.\relax }}{10}{figure.caption.25}\protected@file@percent }
\newlabel{fig:ffrec_symmetrized}{{1.6}{10}{\textbf {Positive correlation between feedforward recurrent alignment score and eigenvalues of symmetrized network.} Project the inputs to the eigenvectors of symmetrized network to refer the development instead of the projection to the original asymmetric network. The correlation between the alignment score (y-axis) based on the original recurrent network to the eigenvalues of symmetrized network (x-axis) remains positive.\relax }{figure.caption.25}{}}
\@writefile{toc}{\contentsline {paragraph}{Conclusion}{11}{section*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2}Representing Response Properties with modified Feedforward Recurrent Alignment}{11}{subsubsection.28}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Trial-to-trial Correlation}{11}{section*.29}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces \textbf  {Correlation between trial-to-trial correlation and feedforward recurrent alignment with asymmetric recurrent network inclusive the influence of symmetry.} For different degree of symmetry $a$, different color dots are applied shown in legend. The green color with $a=1.0$ illustrates the case of symmetric network. The most dark purple $a=0.0$ represents the asymmetric network without any influence of symmetry. The x-axis shows the alignment score calculated with considered modifications and the y-axis indicates the trial-to-trial correlation calculated with aligned inputs through (\ref  {eq:ttc_sym}) \textbf  {Left}: Result generated with modification 1 (only consider real part). \textbf  {Right}: Result with modification 3 (symmetrized recurrent network).\relax }}{12}{figure.caption.30}\protected@file@percent }
\newlabel{fig:ttc_asym}{{1.7}{12}{\textbf {Correlation between trial-to-trial correlation and feedforward recurrent alignment with asymmetric recurrent network inclusive the influence of symmetry.} For different degree of symmetry $a$, different color dots are applied shown in legend. The green color with $a=1.0$ illustrates the case of symmetric network. The most dark purple $a=0.0$ represents the asymmetric network without any influence of symmetry. The x-axis shows the alignment score calculated with considered modifications and the y-axis indicates the trial-to-trial correlation calculated with aligned inputs through (\ref {eq:ttc_sym}) \textbf {Left}: Result generated with modification 1 (only consider real part). \textbf {Right}: Result with modification 3 (symmetrized recurrent network).\relax }{figure.caption.30}{}}
\@writefile{toc}{\contentsline {paragraph}{Intra-trial Stability}{12}{section*.31}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces \textbf  {Correlation between intra-trial stability and feedforward recurrent alignment with asymmetric recurrent network considering the influence from degree of symmetry.} For multiple degrees of symmetry $a$, different color dots are applied shown in legend. From complete symmetric $a = 1.0$ (as control) to full asymmetric recurrent network, the corresponding feedforward recurrent alignment (x-axis) is plotted against the intra-trial stability (y-axis). \textbf  {Left}: Result with modification 1 (only real part of aligned inputs). \textbf  {Right}: Result with modification 3 (align input to symmetrized network).\relax }}{13}{figure.caption.32}\protected@file@percent }
\newlabel{fig:its_asym}{{1.8}{13}{\textbf {Correlation between intra-trial stability and feedforward recurrent alignment with asymmetric recurrent network considering the influence from degree of symmetry.} For multiple degrees of symmetry $a$, different color dots are applied shown in legend. From complete symmetric $a = 1.0$ (as control) to full asymmetric recurrent network, the corresponding feedforward recurrent alignment (x-axis) is plotted against the intra-trial stability (y-axis). \textbf {Left}: Result with modification 1 (only real part of aligned inputs). \textbf {Right}: Result with modification 3 (align input to symmetrized network).\relax }{figure.caption.32}{}}
\@writefile{toc}{\contentsline {paragraph}{Dimensionality}{14}{section*.33}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces \textbf  {Analytical and empirical effective dimensionality in correlation with feedforward recurrent alignment with asymmetric recurrent network. Impact on the correlation from the degree of symmetry in network.} The full symmetric recurrent network ($a = 1.0$) is control for other cases with $a < 1.0$. When $a = 0.0$, the recurrent network is fully asymmetric. The dots represents the empirical approximation for effective dimensionality (\ref  {eq:dim_empirical_sym}). The lines are for the analytical calculation for dimensionality adjusted to modification 1 and 3 (section \ref  {sec:modification_asym} eq. (\ref  {eq:modifications_dim}), (\ref  {eq:modification_eff_dim})). \textbf  {Left}: Result with modification 1 (only real part of aligned inputs and eigenvalues for analytical dimensionality). \textbf  {Right}: Result with modification 3 (align inputs and to symmetrized recurrent network).\relax }}{14}{figure.caption.34}\protected@file@percent }
\newlabel{fig:dim_asym}{{1.9}{14}{\textbf {Analytical and empirical effective dimensionality in correlation with feedforward recurrent alignment with asymmetric recurrent network. Impact on the correlation from the degree of symmetry in network.} The full symmetric recurrent network ($a = 1.0$) is control for other cases with $a < 1.0$. When $a = 0.0$, the recurrent network is fully asymmetric. The dots represents the empirical approximation for effective dimensionality (\ref {eq:dim_empirical_sym}). The lines are for the analytical calculation for dimensionality adjusted to modification 1 and 3 (section \ref {sec:modification_asym} eq. (\ref {eq:modifications_dim}), (\ref {eq:modification_eff_dim})). \textbf {Left}: Result with modification 1 (only real part of aligned inputs and eigenvalues for analytical dimensionality). \textbf {Right}: Result with modification 3 (align inputs and to symmetrized recurrent network).\relax }{figure.caption.34}{}}
\@writefile{toc}{\contentsline {paragraph}{Alignment to spontaneous activity}{15}{section*.36}\protected@file@percent }
\newlabel{SC@4}{{\caption@xref {??}{ on input line 323}}{15}{Alignment to spontaneous activity}{figure.caption.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.10}{\ignorespaces \textbf  {The correlation between alignment to spontaneous activity and feedforward recurrent alignment considering influence from degree of symmetry in the recurrent network.} As control, fully symmetric recurrent network $a=1.0$ is represented with dark green dots. For different degree of symmetry from $a = 0.75$ to $0$, the darker the dot color, the more asymmetric is the recurrent network. \relax }}{15}{figure.caption.37}\protected@file@percent }
\newlabel{fig:align_to_spont_asym}{{1.10}{15}{\textbf {The correlation between alignment to spontaneous activity and feedforward recurrent alignment considering influence from degree of symmetry in the recurrent network.} As control, fully symmetric recurrent network $a=1.0$ is represented with dark green dots. For different degree of symmetry from $a = 0.75$ to $0$, the darker the dot color, the more asymmetric is the recurrent network. \relax }{figure.caption.37}{}}
\@writefile{toc}{\contentsline {paragraph}{Conclusion}{15}{section*.38}\protected@file@percent }
\citation{mastrogiuseppe2018linking}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Modeling Feedforward Recurrent Alignment Hypothesis on Low-rank Recurrent Neural Networks (RNNs)}{17}{subsection.39}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1}Evaluation of Feedforward Recurrent Alignment in symmetric Low-rank RNNs based on response properties considering different Constructions}{17}{subsubsection.40}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Low-rank RNNs without random noise}{17}{section*.41}\protected@file@percent }
\newlabel{SC@5}{{\caption@xref {??}{ on input line 351}}{17}{Low-rank RNNs without random noise}{figure.caption.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.11}{\ignorespaces \textbf  {Eigenvalue distribution of low-rank RNNs without random noise.} The eigenvalues of symmetric low-rank RNNs are real numbers (x-axis). With rank $G = 1 \ll n = 200$ the number of neurons, number of $G = 1$ eigenvalues takes the value of normalization factor $R = 0.85 < 1$ and the rest $n-G = 199$ number of eigenvalues equal $0$. \relax }}{17}{figure.caption.42}\protected@file@percent }
\newlabel{fig:eigval_low_rank_without_noise}{{1.11}{17}{\textbf {Eigenvalue distribution of low-rank RNNs without random noise.} The eigenvalues of symmetric low-rank RNNs are real numbers (x-axis). With rank $G = 1 \ll n = 200$ the number of neurons, number of $G = 1$ eigenvalues takes the value of normalization factor $R = 0.85 < 1$ and the rest $n-G = 199$ number of eigenvalues equal $0$. \relax }{figure.caption.42}{}}
\newlabel{eq:sym_low_rank_eigval}{{1.11}{18}{Low-rank RNNs without random noise}{equation.43}{}}
\newlabel{}{{1.12a}{19}{\relax }{figure.caption.45}{}}
\newlabel{sub@}{{a}{19}{\relax }{figure.caption.45}{}}
\newlabel{}{{1.12b}{19}{\relax }{figure.caption.45}{}}
\newlabel{sub@}{{b}{19}{\relax }{figure.caption.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.12}{\ignorespaces \textbf  {Trial-to-trial correlation and intra-trial stability in correlation with feedforward recurrent alignment score for low-rank symmetric RNNs.} \textbf  {(a)} Trial-to-trial correlation in relationship with feedforward recurrent alignment. \textbf  {(b)} Intra-trial stability in relationship with feedforward recurrent alignment.  The positive correlation between feedforward recurrent alignment and trial-to-trial correlation \textbf  {(a)} or intra-trial stability \textbf  {(b)} is discontinuous due to the number of eigenvalues under low rank. If having rank $G = 1$, only one feedforward recurrent alignment score take the value $R = 0.85$, correlating with large trial-to-trial correlation \textbf  {(a)} or intra-trial stability \textbf  {(b)}. The rest concentrates at alignment score $0$ with low trial-to-trial correlation \textbf  {(a)} or low intra-trial stability \textbf  {(b)}. \relax }}{19}{figure.caption.45}\protected@file@percent }
\newlabel{fig:ttc_its_low_rank_sym_no_noise}{{1.12}{19}{\textbf {Trial-to-trial correlation and intra-trial stability in correlation with feedforward recurrent alignment score for low-rank symmetric RNNs.} \textbf {(a)} Trial-to-trial correlation in relationship with feedforward recurrent alignment. \textbf {(b)} Intra-trial stability in relationship with feedforward recurrent alignment.\\ The positive correlation between feedforward recurrent alignment and trial-to-trial correlation \textbf {(a)} or intra-trial stability \textbf {(b)} is discontinuous due to the number of eigenvalues under low rank. If having rank $G = 1$, only one feedforward recurrent alignment score take the value $R = 0.85$, correlating with large trial-to-trial correlation \textbf {(a)} or intra-trial stability \textbf {(b)}. The rest concentrates at alignment score $0$ with low trial-to-trial correlation \textbf {(a)} or low intra-trial stability \textbf {(b)}. \relax }{figure.caption.45}{}}
\@writefile{toc}{\contentsline {paragraph}{Low-rank RNNs with random noise}{19}{section*.46}\protected@file@percent }
\newlabel{eq:low_rank_sym_with_noise}{{1.13}{20}{Low-rank RNNs with random noise}{equation.47}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.13}{\ignorespaces \textbf  {Correlation between response properties and feedforward recurrent alignment in low-rank RNNs with random noise.} Besides the part of a low-rank matrix with rank $G$, RNNs with noise includes an extra part of symmetrized random Gaussian matrix (\ref  {eq:low_rank_sym_with_noise}). The rank of low rank part has the rank $G=1$.  \textbf  {(a)} Trial-to-trial correlation (y-axis) against feedforward recurrent alignmnet score (x-axis). \textbf  {(b)} Intra-trial stability (y-axis) against feedforward recurrent alignment score (x-axis). \textbf  {(c)} Dimensionality (y-axis) in dependence of feedforward recurrent alignment score (x-axis). \textbf  {(d)} Alignment to spontaneous activity (y-axis) against feedforward recurrent alignment (x-axis).\relax }}{20}{figure.caption.48}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Conclusion}{21}{section*.49}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.2}Different Constructions influence the impact of rank in asymmetric Low-rank RNNs based on response properties}{21}{subsubsection.50}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Low-rank RNNs without random noise}{21}{section*.51}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Low-rank RNNs with random noise}{22}{section*.52}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Conclusion}{22}{section*.53}\protected@file@percent }
\gdef \@abspage@last{22}
